# Sign Language Interpreter

This project uses a neural network to interpret American Manual Alphabet gestures in real time. The neural network consists of a single hidden layer with 350 neurons and an input layer of 784 neurons. The neural network was trained using the MNIST sign language dataset that can be found [here]. 

## Screenshots

![Screenshot 1](images/clip1.gif "Screenshot 1")
![Screenshot 2](images/clip2.gif "Screenshot 2")
![Screenshot 3](images/clip3.gif "Screenshot 3")

[here]: https://www.kaggle.com/datamunge/sign-language-mnist